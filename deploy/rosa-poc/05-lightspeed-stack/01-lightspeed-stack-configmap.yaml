apiVersion: v1
kind: ConfigMap
metadata:
  name: lightspeed-stack-config
  namespace: lightspeed-poc
data:
  lightspeed-stack.yaml: |
    name: Lightspeed Core Service - ROSA POC
    service:
      host: 0.0.0.0
      port: 8080
      auth_enabled: false
      workers: 1
      color_log: true
      access_log: true
      cors:
        allow_origins:
          - "*"
        allow_credentials: false
        allow_methods:
          - "*"
        allow_headers:
          - "*"

    llama_stack:
      use_as_library_client: false
      url: http://llama-stack-service.lightspeed-poc.svc.cluster.local:8321
      api_key: xyzzy

    user_data_collection:
      feedback_enabled: true
      feedback_storage: "/tmp/data/feedback"
      transcripts_enabled: true
      transcripts_storage: "/tmp/data/transcripts"

    authentication:
      module: "noop"

    customization:
      system_prompt: |
        You are a helpful AI assistant with expertise in Red Hat OpenShift AI.
        You have access to a knowledge_search tool that contains documentation about Red Hat OpenShift AI.

        IMPORTANT: When users ask questions about Red Hat OpenShift AI, RHOAI, model serving, inference, or related topics,
        ALWAYS use the knowledge_search tool FIRST to find accurate information from the documentation before answering.

        After searching the knowledge base, provide comprehensive answers based on the retrieved information.
        If the knowledge base doesn't contain relevant information, you can answer based on your general knowledge,
        but make it clear that the information is not from the official documentation.

        Be helpful, accurate, and concise in your responses.
